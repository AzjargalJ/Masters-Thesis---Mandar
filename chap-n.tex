\chapter{Experiments}
\label{cha:n}
The experiments are performed on a 40 core 64GB RAM machine at the Department of Electrical Engineering, KU Leuven. The experiment parameters are summarized in table \ref{table:param}. We use the \textit{Magic Gamma} Telescope, and \textit{Adult} data sets available from the UCI Machine Learning Repository \cite{Lichman:2013}. The performance of various kernel based FS-LSSVM models is carried out for various experimental parameters, each set of experiments is repeated thrice, the mean and standard deviation (in brackets), of the area under ROC curve and the classification accuracy are recorded and presented in tables \ref{table1} and \ref{table2}.

\begin{itemize}
\item Magic Gamma: The data is generated by the registration of high speed gamma particles measured by a ground based atmospheric Cherenkov gamma telescope. Each entry consists of 10 numerical attributes and a binary class attribute. 
\item Adult: This is based on a a census study carried out in 1994, the data consists of 6 numerical attributes and 8 categorical attributes. The target attribute is binary class value, which indicates if the given individual has an annual income more than $50 000$\$.
\end{itemize}

\begin{table*}[!htbp]
\caption{Experiment Parameters}
\label{table:param}
\centering
\adjustbox{max width=\textwidth}{
\begin{tabular}{ |c|c| }
\hline
Name & Meaning \\
\hline
Kernel & The type of kernel used i.e. RBF, Polynomial, etc \\ 
Prototypes & Size of prototype set \\ 
Global Opt. & Hyper-parameter optimization algorithm i.e. gs: Grid Search, csa: Coupled Simulated Annealing \\
Grid Size & Number of points (per hyper-parameter) in the grid  \\
Grid Resolution & Distance between two adjacent points on each axis of the grid \\
Scale & Determines if the grid is on the logarithmic scale or linear \\
F1 score & avg. F1 score (measure of classification accuracy) \\
area under ROC & avg. area under the ROC curve \\
\hline
\end{tabular}
}
\end{table*}

%\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
%\caption{An Example of a Table}
%\label{table_example}
%\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
%\begin{tabular}{|c||c|}
%\hline
%One & Two\\
%\hline
%Three & Four\\
%\hline
%\end{tabular}
%\end{table}



The performance of binary FS-LSSVM classifiers on the \textit{MAGIC Gamma} Telescope Data Set obtained from the UCI Machine Learning Repository, are summarized in Table \ref{table1}. FS-LSSVM models trained with polynomial kernels give better classification performance than the RBF and Linear counterparts, on the \textit{MAGIC Gamma} data.

\DTLloaddb{magicgamma}{resultsMagicGammaProc.csv}
\begin{table*}[!htbp]
\caption{Magic Gamma Test Results}
\begin{center}
\adjustbox{max width=\textwidth}{
\begin{tabular}{|l|l|l|l|l|l|l|l|}\label{table1}
\bfseries Kernel & \bfseries Prototypes & \bfseries Global Optimization & \bfseries Grid Size & \bfseries Grid Resolution & \bfseries Scale & \bfseries max F1 score & \bfseries Area under ROC%
\DTLforeach{magicgamma}{\kernel=kernel,\prototypes=prototypes,
\globaloptimization=globaloptimization,\gridsize=gridsize,
\gridresolution=gridresolution,\scale=scale,\maxF=maxF1score,
\stdF=stdF,\areaunderROC=areaunderROC,\stdR=stdR}%
{%
  \\\kernel & \prototypes & \globaloptimization & \gridsize & \gridresolution & \scale & $\maxF(\stdF)$ & $\areaunderROC(\stdR)$
}%
\end{tabular}
}
\end{center}
\end{table*}

The performance of binary FS-LSSVM classifiers on the \textit{Adult} Data Set, are summarized in Table \ref{table2}. FS-LSSVM models trained with exponential kernels give better classification performance than the RBF and Linear counterparts, on the \textit{Adult} data. For both the data sets one sees a pattern emerging that tuning kernel models with CSA gives better results than naive \textit{Grid Search} based hyper-parameter optimization.

\DTLloaddb{adultres}{adultres.csv}
\begin{table*}[!htbp]
\caption{Adult Data Set Test Results}
\begin{center}
\adjustbox{max width=\textwidth}{
\begin{tabular}{|l|l|l|l|l|l|l|l|}\label{table2}
\bfseries Kernel & \bfseries Prototypes & \bfseries Global Optimization & \bfseries Grid Size & \bfseries Grid Resolution & \bfseries Scale & \bfseries max F1 score & \bfseries Area under ROC%
\DTLforeach{adultres}{\kernel=kernel,\prototypes=prototypes,
\globaloptimization=globaloptimization,\gridsize=gridsize,
\gridresolution=gridresolution,\scale=scale,\maxF=maxF1score,
\stdF=stdF,\areaunderROC=areaunderROC,\stdR=stdR}%
{%
  \\\kernel & \prototypes & \globaloptimization & \gridsize & \gridresolution & \scale & $\maxF(\stdF)$ & $\areaunderROC(\stdR)$
}%
\end{tabular}
}
\end{center}
\end{table*}

\section{Conclusion} \label{Conclusion}

In this paper \textit{FS-Scala}, a Scala-based implementation for training and tuning kernel based FS-LSSVM models. As a use case, the kernel based FS-LSSVM model is tested on benchmark data sets. We observed that our implementation enables scalable training, tuning and evaluation of models learning from Big Data, while still providing flexibility to tweak various underlying data processing infrastructure.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "thesis"
%%% End: 
