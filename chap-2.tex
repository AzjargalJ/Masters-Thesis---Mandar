\chapter{FS-Scala}
\label{cha:2}

\section{Scientific Computing: An Overview}
The term \textit{Scientific Programming} must be interpreted with proper context, as the very first applications of the primitive computational infrastructure developed during the second world war were conducting numerical simulations of various engineering problems of practical significance. It must thus be recognized that only after large scale adoption of computers for business applications became popular, that the term \textit{Scientific Computing} became relevant as a sub-domain of Computer Science.

Nevertheless it is instructive to take a quick glance at the history of programming languages in order to motivate the design philosophy behind \textit{FS-Scala} and the \textit{MapReduce} computational paradigm which has been applied extensively in modern large scale data processing frameworks.

We classify programming languages on two broad issues, for an in-depth treatment of the subject one may refer to some of the canonical texts in the area \cite{Sethi:1989}, \cite{Abelson:1996:SIC:547755}.

\begin{itemize}
\item Translation to Machine level code.
Programs written in any language have to be translated to low level machine readable instructions or codes, this may be achieved in two ways.
\begin{itemize}
\item Compilation: The high level program is "compiled" or translated into low level executable code, this is achieved in various ways on different platforms (i.e. .exe file on Windows based systems, .sh files on *nix systems). Note that this process has to be done once and the executable code can be run many times.

\item Interpretation: Instead of translating the high level code before hand, an interpreter translates all the content of a program into low level instructions every time it is executed.

\end{itemize}

\item Paradigms.

\begin{itemize}
\item Imperative Programming.
Programs consist of instructions which modify a given 'state', which may refer to a memory location or variable.
\item Object Oriented Programming (OOP).
Programs consist of entities called 'objects' which contain data, called 'fields' and subroutines to modify their data.
\item Functional Programming (FP).
Programs consist of expressions which take input and output the results, its worth noting that the input and output data structures are immutable. It is worth noting that in Functional Programming one may pass a function itself as an argument to another function/subroutine, this behavior is colloquially referred to by the phrase "code as data". 
\end{itemize}
\end{itemize}

There are advantages and limitations of each programming language or paradigm, which must be understood before choosing one for a particular application. It is well known that compiled languages have much better performance than interpreted languages, though one must keep in mind that being compiled or interpreted are not inherent characteristics of the languages themselves rather practical implementation details. This advantage that languages like C and Fortran possess is evidenced in the fact that much of the Python scientific programming frameworks use underlying \textit{C} or \textit{Fortran} primitives for fast computation, \textit{scikit-learn} \cite{scikit-learn} being the best example.

So far \textit{Python} and \textit{MATLAB} have been the dominant languages used in computation for engineering and science applications, this is because of their ease of learning with respect to syntax and the ready availability of packages which can be used to extend their capability for specific applications like signal processing (in \textit{MATLAB}) and Natural Language Processing (see \textit{NLTK} \cite{NLTK} ) in \textit{python}.

While \textit{python} and \textit{MATLAB} are convenient for quick prototyping of new algorithms and models, for production machine learning systems their performance makes them unsuitable for those applications. The most common languages used for production systems are \textit{C/C++} and \textit{Java}. The Java Virtual Machine (JVM) has become a standard platform for enterprise applications in the past two decades. The \textit{Apache Hadoop} and \textit{Mahout} big data and machine learning frameworks are written entirely in \textit{Java}. As such, the JVM offers a sound platform for future efforts in large scale machine learning. One of the recent developments has been the development of JVM based languages which have embraced the FP paradigm along with the inherent Object Oriented (OO) nature of the \textit{Java} language and the JVM.

\subsection*{Scala, MapReduce and Data Processing}

\textit{Scala} is a hybrid, multi-paradigm language developed at the EPFL, Lausanne in 2004 \cite{scala-overview-tech-report}. It is a JVM based language because all \textit{Scala} code is translated to JVM byte code to be execute like any other Java program. This gives it seamless interpolability with Java and all the programming frameworks written in Java. It is primarily an OOP language which has many functional characteristics like support for \textit{tail recursive} optimization, function composition and immutable data structures. Its is inspired by many prominent FP languages like \textit{Lisp}, \textit{Haskell}, \textit{OCaml} etc.

An important concept or paradigm espoused in many FP languages is \textit{MapReduce}, it can be readily observed that many programs/computations in languages like \textit{Lisp}, \textit{Scala} use \textit{MapReduce} on immutable data structures like lists in order to obtain results. In chapter \ref{cha:3} we delve further into the \textit{MapReduce} paradigm and why it is so central to modern big data architectures. It is instructive to note that in \textit{Scala}, data structures like lists, maps and so on have in built \texttt{map} and \texttt{reduce} functions which enable the programmer to think and code in this paradigm.

It is for these reasons that \textit{Scala} has become crucial to the implementation of modern big data frameworks like \textit{Apache Spark} and the language of choice for us in the implementation of the FS-LSSVM.

\begin{figure}[!ht] 
\begin{adjustbox}{max width=\textwidth}
\begin{tikzpicture}[mindmap,
  level 1 concept/.append style={level distance=110,sibling angle=40},
  extra concept/.append style={color=blue!50,text=black}]

  % Applied area: computer science and its subfields

  \begin{scope}[mindmap, concept color=orange, text=white]
    \node [concept] (comp) {Compiled}[clockwise from=3]
        child {node [concept] (c) {C}}
        child {node [concept] (java) {Java}}
        child {node [concept] (fortran) {Fortran}}
        child[level distance=140] {node [concept] (julia) {Julia}}
        child {node [concept] (scala) {Scala}};
  \end{scope}
  
  \begin{scope}[mindmap, concept color=blue]
    \node [concept, text=white] (int) at (15,-14) {Interpreted}
        child [concept color=blue!50, grow=85, level distance=190] 
            {node [concept] (matlab) {MATLAB}}
        child [concept color=blue!50, grow=130, level distance=120] 
            {node [concept] (py) {Python}}
        child [concept color=blue!50, grow=190, level distance=120] 
            {node [concept] (r) {R}};
  \end{scope}

  \begin{scope}[mindmap, concept color=red,text=white]
    \node [concept] (fp) at (-2.5,-13) {Functional};
  \end{scope}

  \begin{scope}[mindmap, concept color=green!50!black,text=white]
    \node [concept] (oop) at (4,-8.5) {Object Oriented};
  \end{scope}

  \begin{scope}[mindmap, concept color=violet, text=white]
    \node [concept] (imp) at (10,-3.5) {Imperative};
  \end{scope}

  \begin{pgfonlayer}{background}
    \path (java) to[circle connection bar] (oop);
    \path (java) to[circle connection bar] (imp);
    \path (scala) to[circle connection bar] (fp);
    \path (scala) to[circle connection bar] (oop);
    \path (c) to[circle connection bar] (imp);
    \path (py) to[circle connection bar] (oop);
    \path (py) to[circle connection bar] (imp);
    \path (r) to[circle connection bar] (fp);
    \path (r) to[circle connection bar] (oop);
    \path (julia) to[circle connection bar] (oop);
    \path (julia) to[circle connection bar] (fp);
    \path (matlab) to[circle connection bar] (oop);
    \path (matlab) to[circle connection bar] (imp);
    \path (fortran) to[circle connection bar] (oop);
    \path (fortran) to[circle connection bar] (imp);
  \end{pgfonlayer}
\end{tikzpicture}
\end{adjustbox}
\caption{Overview of Scientific Computing Languages}
\label{fig:scilang}
\end{figure}

\section{SVM Software: The state of the art}

Since its inception, there have been a number of implementations of the classical soft-margin SVM, one can find a diverse list of software at \cite{SVMSoft}. Notable implementations include \textit{LibSVM} \cite{LibSVM}, \textit{SVM\textsuperscript{Light}} \cite{SVMLight} and \textit{mySVM} \cite{mySVM} among others. With respect to the LSSVM there is an implementation by Suykens et.al \cite{LSSVMLab} called \textit{LSSVMLab} written in \textit{MATLAB}. Below we review salient features of a select subset of SVM software implementations.

\begin{itemize}
\item LibSVM: A C/C++ software package that supports Support Vector Classification (C-SVC and \textnu-SVC),  Regression (\textepsilon-SVR and \textnu-SVR) and Density Estimation. It supports binary as well as multi-class classification. Weighted training for unbalanced data sets, along with support for kernels (precomputed and non precomputed kernel matrices). It also supports Sequential Minimal Optimization (SMO) based training of SVM models. One of the most popular SVM implementations with several language ports and multiple libraries (ex. Scikit Learn \cite{scikit-learn}) which use it as a back-end SVM model builder. 

\item SVM\textsuperscript{Light}: A C based software package that aims to reduce the training times for SVM models using faster optimization algorithms which are achieved by a combination of kernel evaluation caching, heuristics and support vector selection based on \textit{steepest feasible descent}. Recently a new implementation \textit{SVM\textsuperscript{perf}} has also been introduced to further speed up model training compared to \textit{SVM\textsuperscript{light}} for large data sets and to optimize multivariate performance measures like F1 measure, ROC area, etc. For an implementation applicable to structures like trees, one can also use SVM\textsuperscript{struct}. 

\item Apache Spark SVM: This SVM model implementation exists as a part of the \textit{MLLib} machine learning library in the \textit{Apache Spark} big data and cluster computing platform. It is one of the several linear models that are offered in this libraries. \textit{MLLib} comes bundled with optimization algorithms such as SGD and L-BFGS.


\item LSSVMLab: A MATLAB software toolbox to train and test LSSVM models. It has support for kernels as well as Bayesian LSSVM formulations which calculate posterior probability of a model or set of hyper-parameters.

\end{itemize}

\section{FS-Scala: Motivation and Design}
FS-Scala tackles three major issues w.r.t. the implementation of the FS-LSSVM:

\begin{itemize}
\item \textbf{Tuning Kernel Models}:
Since the performance of kernel based models is sensitive with respect to the choice of hyper-parameters, one has to choose a mechanism of model selection or hyper-parameter optimization. In FS-Scala, we implement the Grid Search and Coupled Simulated Annealing global optimization algorithms for model tuning.

\item \textbf{Parallel Computation}\label{mr}:
Big Data analysis requires the distribution of computational work load, \textit{MapReduce} is the dominant paradigm employed for writing distributed data processing programs. In FS-Scala we leverage \textit{MapReduce} to distribute the computation in the pre-processing, training and cross-validation tasks.

\item \textbf{Infrastructure Flexibility}:
The big data landscape has many tools which enable the storage and analysis of large streams of data, they consist of technologies such as, but not limited to \textit{Apache Spark}, \textit{Hadoop}, Graph Databases like \textit{Titan} \cite{Titan:2014}, \textit{OrientDB} \cite{OrientDB:2010}, \textit{Neo4j} \cite{Neo4j:2010}. Creating a powerful framework for model training and evaluation requires the decoupling of storage and processing infrastructure from the actual logic that implements the architecture of learning models.
\end{itemize}

The implementation of the FS-LSSVM in FS-Scala, outlined in algorithm \ref{lssvmalgo}, chapter \ref{cha:1} is as described in the original article of De Brabanter et al. \cite{DeBrabanter2010}. Kernel based models all implement the interface \textit{GloballyOptimizable} in the optimization module (see Figure \ref{fig:modelUML1}). Since the \textit{GlobalOptimizer} and its subclasses (i.e. \textit{GridSearch} and \textit{CoupledSimulated Annealing}) all optimize models which implement the \text{GloballyOptimizable} interface, it enables tuning of models with a variety of global optimization algorithms convenient.

\subsection*{Architecture}
Figure \ref{fig:struct} shows the organization of modules in FS-Scala. It can be decomposed into five principal modules:
\begin{itemize}
\item Model Classes:
This is the core set of classes which form the heart of the library, a number of abstract model categories are defined each with its own set of defined behaviours. 
\item Optimization application programming interface (API):
A module which houses the implementation of common optimization methods (i.e. Gradient and Gradient free). Currently FS-Scala has implementations for Conjugate Gradient, Gradient Descent, Grid Search and Coupled Simulated Annealing \cite{Xavier-De-Souza2010} (CSA). 
\item Kernels:
FS-Scala is equipped with a powerful abstract API for representing kernel functions. The module has two abstract classes to outline the behaviors of kernels used in SVM based applications as well as density estimation. The library comes bundled with an implementation for AFE as well as for common SVM kernels i.e. Linear, Radial Basis Function (RBF), Polynomial, Laplace, Exponential. New kernel functions can be easily added to the library by extending the base classes in this module.
\item Evaluation Metrics:
We have implemented evaluation metrics for Binary Classification and Regression problems. Further more, the implementation of binary classification performance expressed as the area under Receiver Operating Characteristic (ROC), is carried out using \textit{MapReduce} in a \textit{single pass} fashion through the evaluation data points, which can be seen in algorithm \ref{efmr}. Calculating the area under the ROC curve in a \textit{single pass} fashion greatly increases the speed of the eventual FS-LSSVM source code.
\item Miscellaneous Utilities:
This module contains code to carry out auxiliary tasks for model learning and optimization. It contains the implementation of entropy calculation, summary statistics, prototype selection as well as a set of various functions which can be required for implementing new model classes using the library.  

\end{itemize}

The FS-Scala software is available at \cite{fsscala}.



\begin{figure}[ht] 
\begin{adjustbox}{max width=0.85\textwidth}
\begin{tikzpicture} [mindmap, grow cyclic, every node/.style=concept, concept color=orange!40, 
    level 1/.append style={level distance=4cm,sibling angle=72},
    level 2/.append style={level distance=3cm,sibling angle=45},]
\node{FS-Scala}
   child [concept color=blue!30]{ node {Model Classes}
        child { node {LSSVM Spark Model}}
        child { node {Kernel Spark Model}}
    }
    child [concept color=brown!30]{ node {Kernels}
        child { node {Mercer Kernels}}
        child { node {Density Estimation Kernels}}
    }
    child [concept color=teal!30]{ node {Optimization}
        child { node {Gradient Based}}
        child { node {Conjugate Gradient}}
        child { node {Global Optimization}}
    }
    child [concept color=purple!30]{ node {Evaluation Metrics}
        child { node {Classification}}
        child { node {Regression}}
    }
    child [concept color=green!30]{ node {Miscellaneous Utilities}
        child { node {Prototype Selection}}
        child { node {Summary Statistics}}
        child { node {Entropy Computation}}
    };

\end{tikzpicture}
\end{adjustbox}
\caption{Schematic structure of FS-Scala}
\label{fig:struct}
\end{figure}



%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "thesis"
%%% End: 
